{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# erg 文件处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  将指定文件夹下的所有 erg 文件合并为一个 csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将 `path` 修改为 erg 文件所在的路径\n",
    "  - 注意不要去掉示例中字符串 `r\"D:\\工作\\2020\\3月\\UAES_C1.1_SPLIT\\torque characteristic\\Motor\\400V\" ` 前的 `r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T03:28:43.257072Z",
     "start_time": "2020-05-09T03:26:53.312249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成!\n"
     ]
    }
   ],
   "source": [
    "# ***\n",
    "# 需要修改的参数\n",
    "path = r\"D:\\工作\\2020\\6月\\erg file\\test\"   # 文件夹路径\n",
    "# ***\n",
    "\n",
    "from file_operator import FileOperator\n",
    "import os\n",
    "\n",
    "file_operator = FileOperator(path)\n",
    "file_operator.handle_ergs(merge=True,\n",
    "                  file_name=os.path.join(path, path.split(os.path.sep)[-1] + '_merge_data.csv'),\n",
    "                  save_to_file=True)\n",
    "print(\"转换完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  将指定文件夹下的所有 erg 文件转换为单独的 csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- 将 `path` 修改为 erg 文件所在的路径\n",
    "  - 注意不要去掉示例中字符串 `r\"D:\\工作\\2020\\3月\\UAES_C1.1_SPLIT\\torque characteristic\\Motor\\400V\" ` 前的 `r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成!\n"
     ]
    }
   ],
   "source": [
    "# ***\n",
    "# 需要修改的参数\n",
    "path = r\"D:\\工作\\2020\\6月\\erg file\"   # 文件夹路径\n",
    "# ***\n",
    "\n",
    "from file_operator import FileOperator\n",
    "import os\n",
    "\n",
    "file_operator = FileOperator(path)\n",
    "file_operator.handle_ergs(merge=False, save_to_file=True)\n",
    "\n",
    "print(\"转换完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 将指定的 erg 文件转换为 csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- 将 file_name 修改为要转换的 erg 文件\n",
    "  - 注意不要去掉示例中字符串 `r\"D:\\工作\\2020\\3月\\UAES_C1.1_SPLIT\\torque characteristic\\Motor\\400V\\60s.erg\" ` 前的 `r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T02:54:11.953151Z",
     "start_time": "2020-05-09T02:53:14.603642Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成!\n"
     ]
    }
   ],
   "source": [
    "file_name = r\"D:\\工作\\2020\\6月\\python-study-group\\课件\\第 1 课 Python 实例\\data\\lavida_53ah_vp432_konditionierung_73.0_001hz.erg\"  # erg 文件夹名称\n",
    "\n",
    "from file_operator import FileOperator\n",
    "import os\n",
    "\n",
    "\n",
    "file_operator = FileOperator(file_name)\n",
    "file_operator.handle_ergs(merge=False, save_to_file=True)\n",
    "print('转换完成!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 按工况点求均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 针对一个文件夹的所有文件或者某个特定的文件，按工况点求取平均值\n",
    "\n",
    "- Arguments:\n",
    "    - file_operator[FileOperator]: FileOperator 对象\n",
    "    - flags[list]: 工况点的标识信号，如 [speed, toruqe]\n",
    "    - save_to_file[bool]: 为 True 则将结果写入文件， 为 False 则不写入文件\n",
    "    -  file_type[str]: 要处理的文件类型, 'csv' 表示 csv 文件 '.erg' 表示 .erg 文件\n",
    "    -  file_name[str]: 结果文件的文件名\n",
    "    - head[bool], line_count[int]: \n",
    "        - 如果 line_count 为 None， 不进行任何操作,\n",
    "        - 如果 line_count 不为 None,\n",
    "            - 如果 head 为 True，则取头 line_count 个点, \n",
    "            - 如果 head 为 False, 则取尾 line_count 个点,\n",
    "    - filter_flag[list]: True 表示过滤异常数据，False 表示不过滤异常数据\n",
    "    - PA_signals[list]: filter_flag 为 True 时，则按照此列表中的数据过滤相关信号值，要求信号的绝对值小于 1e10\n",
    "\n",
    "- return\n",
    "    - average_data[DataFrame]: 求完平均值后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成\n"
     ]
    }
   ],
   "source": [
    "# ***\n",
    "# 需要修改的参数\n",
    "\n",
    "file_name = r\"D:\\工作\\2020\\6月\\erg_file\"\n",
    "flags=['speed_step']\n",
    "filter_flag = True\n",
    "PA_signals = ['PA1_PM [W]']\n",
    "file_type = 'erg'\n",
    "\n",
    "head=True\n",
    "line_count=200\n",
    "# ***\n",
    "\n",
    "from file_operator import FileOperator\n",
    "import os\n",
    "from data_process import get_average\n",
    "\n",
    "file_operator = FileOperator(file_name)\n",
    "get_average(file_operator, flags=flags, file_type=file_type, filter_flag=filter_flag, PA_signals=PA_signals, file_name=None, head=True, line_count=line_count, save_to_file=True)\n",
    "\n",
    "print('处理完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 递归的处理文件夹中的所有 erg 文件并求平均值 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- 将 `path` 修改为 erg 文件所在的路径\n",
    "  - 注意不要去掉示例中字符串 `r\"D:\\工作\\2020\\3月\\UAES_C1.1_SPLIT\" ` 前的 `r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = r\"D:\\工作\\2020\\6月\\erg_file\"\n",
    "\n",
    "flags=['speed_step']\n",
    "filter_flag = True\n",
    "PA_signals = ['PA1_PM [W]']\n",
    "file_type = 'erg'\n",
    "\n",
    "head=True\n",
    "line_count=200\n",
    "\n",
    "\n",
    "import os\n",
    "from file_operator import FileOperator\n",
    "\n",
    "for root, dirs, _ in os.walk(path):\n",
    "    for directory in dirs:\n",
    "        sub_path = os.path.join(root, directory)\n",
    "        _file_name =  \"_\".join(sub_path.split(os.path.sep)[len( path.split(os.path.sep) ):])\n",
    "        result_dir = os.sep.join(path.split(os.sep)[:-1] + [path.split(os.sep)[-1] + 'result']\n",
    "                + sub_path.split(os.path.sep)[len(path.split(os.path.sep) ):])\n",
    "        file_operator = FileOperator(sub_path, result_dir)\n",
    "        if file_operator.erg_files:\n",
    "            file_name = os.path.join(result_dir,_file_name+\".csv\")\n",
    "            file_operator.handle_ergs(merge=True, file_name=file_name, save_to_file=True)\n",
    "            new_file_operator = FileOperator(result_dir)\n",
    "            file_name = os.path.join(result_dir,\"Average_\"+_file_name+\".csv\")\n",
    "            get_average(file_operator, flags=flags, file_type=file_type, filter_flag=filter_flag, PA_signals=PA_signals, file_name=file_name, head=True, line_count=line_count, save_to_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 转换 DIAdem (.dat) 至 csv 文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- data_file 参数\n",
    "  - 需要修改为 dat 文件，需要是文件，暂不支持目录\n",
    " - 由于 excel 会限制打开文件时显示的行数，因此当记录超过 $2^{20}$ 后，会分为多个 csv 文件进行储存，确保单个 csv 文件的行数不超过 $2^{20}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ***\n",
    "# 需要修改的参数\n",
    "dat_file = r\"D:\\其它\\tmp\\swd_eef_mod_meb_bosch_suv_150kw_40c_100hz.DAT\" # 换为自己的文件\n",
    "\n",
    "# ***\n",
    "\n",
    "import os\n",
    "from collections import namedtuple, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import struct\n",
    "\n",
    "\n",
    "# 处理 data， 获取 head 信息\n",
    "Channel = namedtuple('Channel', 'name, unit, channel_type,file_name, method, data_type, nums, start_index, block_offset')\n",
    "\n",
    "with open(dat_file, encoding='cp1258') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "\n",
    "p = r\"#BEGINCHANNELHEADER\\n(.+?)#ENDCHANNELHEADER\\n\"\n",
    "import re\n",
    "channel_contents = re.findall(p, text, re.DOTALL)\n",
    "\n",
    "if not channel_contents:\n",
    "    with open(dat_file, encoding='utf16') as f:\n",
    "        text = f.read()\n",
    "        for line in f:\n",
    "            print(line)\n",
    "    channel_contents = re.findall(p, text, re.DOTALL)\n",
    "\n",
    "channels = []\n",
    "for channel_content in channel_contents:\n",
    "    contents = channel_content.split('\\n')\n",
    "    dic = {}\n",
    "    for content in contents:\n",
    "        l = content.split(',')\n",
    "        if len(l)>=2:\n",
    "            dic[int(l[0])] = l[1]\n",
    "    if dic.get(213) == 'BLOCK':\n",
    "        channels.append(Channel(dic.get(200), dic.get(202), dic.get(210), dic.get(211), dic.get(213), dic.get(214), \n",
    "                                int(dic.get(220)),int(dic.get(221)), int(dic.get(222))))\n",
    "    else:\n",
    "        channels.append(Channel(dic.get(200), dic.get(202), dic.get(210), dic.get(211), dic.get(213), dic.get(214), int(dic.get(220)), int(dic.get(221)), None))\n",
    "\n",
    "\n",
    "\n",
    "# 获取数据文件\n",
    "datas = {}\n",
    "datatypes = {'REAL32': 'f', 'REAL64':'d', 'INT16': 'h', 'INT32':'i'}\n",
    "channel_datas = {}\n",
    "for channel in channels:\n",
    "    if channel.channel_type != 'EXPLICIT':\n",
    "        raise Exception(\"Channel type {} is not supported\".format(channel.channel_type))\n",
    "        \n",
    "    if channel.data_type not in datatypes:\n",
    "        raise TypeError(\"Data Type {} is not supported in this version.\".format(channel.data_type))\n",
    "        \n",
    "    if channel.file_name not in datas:\n",
    "        datas[channel.file_name] = memoryview(open(os.path.join(os.path.split(dat_file)[0], channel.file_name), 'rb').read())\n",
    "        \n",
    "    if channel.unit is not None:\n",
    "        channel_name = \"{} [{}]\".format(channel.name, channel.unit)\n",
    "    else:\n",
    "        channel_name = channel.name\n",
    "    \n",
    "    if channel.method == 'CHANNEL':\n",
    "        channel_datas[channel_name] = datas[channel.file_name].cast(datatypes[channel.data_type])[channel.start_index - 1:channel.start_index + channel.nums - 1]\n",
    "    elif channel.method == 'BLOCK':\n",
    "        channel_datas[channel_name] = datas[channel.file_name].cast(datatypes[channel.data_type])[channel.start_index - 1::channel.block_offset]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(channel_datas)\n",
    "number_of_chunks = math.ceil(len(df) / 2** 20)\n",
    "for id, df_i in enumerate(np.array_split(df, number_of_chunks)):\n",
    "    df_i.to_csv('{}_{}.csv'.format(os.path.splitext(dat_file)[0], id+1), index=0, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同时处理一个试验项目的多个工况点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行完成，结果在文件夹:\n",
      " D:\\工作\\2020\\6月\\python-study-group\\课件\\第 1 课 Python 实例\\data\\01 open_circuit\\20 ℃\\result\n",
      "运行完成，结果在文件夹:\n",
      " D:\\工作\\2020\\6月\\python-study-group\\课件\\第 1 课 Python 实例\\data\\01 open_circuit\\65 ℃\\result\n"
     ]
    }
   ],
   "source": [
    "from file_operator import FileOperator\n",
    "from handle_single_working import HandleSingleWorking\n",
    "\n",
    "path = r\"D:\\工作\\2020\\6月\\python-study-group\\课件\\第 1 课 Python 实例\\data\\01 open_circuit\"\n",
    "\n",
    "file_operator = FileOperator(path)\n",
    "\n",
    "for path in file_operator.get_subfolder():\n",
    "    HandleSingleWorking(path, 'open_circuit', 2).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
